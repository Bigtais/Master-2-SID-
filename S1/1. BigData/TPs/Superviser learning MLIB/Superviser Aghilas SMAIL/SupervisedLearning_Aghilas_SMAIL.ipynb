{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cc7dd1b-8abc-4f15-b71b-0cec73da59ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Pour tester les 2 algorithmes, il faut prendre ces codes dans le notebook de base, et de l'exécuter, je ne suis pas arrivé à télécharger le notebook de base car j'ai dépassé les 10 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29372f21-fc94-4786-b622-f257cb59f8c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#1. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "494a11f6-a939-4829-ac8c-ee2c29d87368",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Étape1. Définir le modèle d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb506fdf-b059-4394-b5da-ee5613ea493e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "svm = LinearSVC(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23f79a20-679c-47bf-8cf7-1299dee4fb39",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Étape 2. Construisez le pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5ab9982-1bac-48d5-9c8b-63725ca1a849",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n|income|count|\n+------+-----+\n| <=50K|24720|\n|  >50K| 7841|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# check class imbalance before creating the pipeline\n",
    "class_distribution = dataset.groupBy('income').count().orderBy('income')\n",
    "class_distribution.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7be60f7a-9f63-40f7-ad30-41aa0d09e383",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline(stages=[stringIndexer, encoder, labelToIndex, vecAssembler, svm])\n",
    "\n",
    "# Define the pipeline model.\n",
    "pipelineModel1 = pipeline1.fit(trainDF)\n",
    "\n",
    "# Apply the pipeline model to the test dataset.\n",
    "predDF1 = pipelineModel1.transform(testDF)\n",
    "\n",
    "display(predDF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4daab2d-3b15-45f9-b41c-bf9b6cfda938",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "display the basic rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70bbd415-c9ec-4856-ac57-e5277b225bce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(predDF1.select(\"features\",\"rawPrediction\", \"prediction\", \"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c61ab6f0-cf82-40ed-aac3-f367a25afe19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|prediction|count|\n+----------+-----+\n|       0.0| 6394|\n|       1.0|   91|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# see if transformations, such as encoding and assembling affect the balance\n",
    "class_distribution_after_pipeline = predDF1.groupBy('prediction').count().orderBy('prediction')\n",
    "class_distribution_after_pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "befac47d-5a6e-4ae4-a4b5-1a70c35504de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "On peut voir que notre data est imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b784b8f9-48df-4ce3-9926-c22bafb50e64",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Etape 3 : Evaluation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "16727071-a43a-4d1c-b265-fb620df1f105",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.884278072268483\nAccuracy: 0.7702390131071704\nrecall : 0.9995925020374898\nF1 Score: 0.6829980614324778\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "bcEvaluator1 = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "print(f\"Area under ROC curve: {bcEvaluator1.evaluate(predDF1)}\")\n",
    "\n",
    "mcEvaluator1 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(f\"Accuracy: {mcEvaluator1.evaluate(predDF1)}\")\n",
    "\n",
    "# Configure the evaluator\n",
    "recallEvaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "print(f\"recall : {recallEvaluator.evaluate(predDF1)}\")\n",
    "\n",
    "# Evaluate the model using MulticlassClassificationEvaluator for F1-Score\n",
    "multi_evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(f\"F1 Score: {multi_evaluator_f1.evaluate(predDF1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d9515a5-cbed-407d-a22f-584d2c789611",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Étape 4. Réglage des hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "072f09ff-06da-4876-b3d2-ed6746496a3c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator, CrossValidatorModel\n",
    "\n",
    "paramGrid1 = ParamGridBuilder() \\\n",
    "    .addGrid(svm.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(svm.maxIter, [10, 100, 1000]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88617558-59f0-4a14-bfde-805d7510dd12",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "crossval1 = CrossValidator(estimator=pipeline1,\n",
    "                          estimatorParamMaps=paramGrid1,\n",
    "                          evaluator=bcEvaluator1,\n",
    "                          numFolds=3)  # Use 3+ folds in practice\n",
    "\n",
    "# Fit the model\n",
    "cvModel = crossval1.fit(trainDF)\n",
    "bestModel = cvModel.bestModel\n",
    "predictions = bestModel.transform(testDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "205689ef-7110-4eda-a8f7-d04c1d7f9847",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.9001913586659108\nAccuracy: 0.8473400154202004\nRecall: 0.9366340668296659\nF1 Score: 0.8400158547740251\n"
     ]
    }
   ],
   "source": [
    "print(f\"Area under ROC curve: {bcEvaluator.evaluate(predictions)}\")\n",
    "print(f\"Accuracy: {mcEvaluator.evaluate(predictions)}\")\n",
    "print(f\"Recall: {recallEvaluator.evaluate(predictions)}\")\n",
    "print(f\"F1 Score: {multi_evaluator_f1.evaluate(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cd49d05-3de2-47b4-8fb9-3e183e13eb44",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### En peut remarqer que l'accuracy et F1 Scors ont augmenter qui dit que notre model a bien été Amélioré. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "776ce2ea-26db-47d6-89f4-b7ff46f56631",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#2. Radom Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d233541d-cb91-4f69-b94d-9a1319abcd60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "### Étape1. Définir le modèle d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1694990-8f1a-462f-9459-289c3c76fbf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# Replace the Logistic Regression with Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee959cae-c6e6-4916-91f8-bad47b363644",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Étape 2. Construisez le pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef13d7e4-cefa-460e-9c75-552097d630d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Define the pipeline based on the stages created in previous steps, replacing lr with rf.\n",
    "pipeline2 = Pipeline(stages=[stringIndexer, encoder, labelToIndex, vecAssembler, rf])\n",
    "# Fit the model\n",
    "pipelineModel2 = pipeline2.fit(trainDF)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predDF2 = pipelineModel2.transform(testDF)\n",
    "display(predDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d3e769b-8a41-4146-8f8b-3495dd51b279",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de colonnes dans le DataFrame : 34\n"
     ]
    }
   ],
   "source": [
    "nombre_de_colonnes = len(predDF2.columns)\n",
    "print(\"Nombre de colonnes dans le DataFrame :\", nombre_de_colonnes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "221adb81-0b09-44e4-b91f-a8061868e161",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(predDF2.select(\"features\",\"rawPrediction\", \"prediction\", \"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84dd13ed-d7a8-48f2-bedd-48c9dcf84bf2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Etape 3 : Evaluation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b4425f4-18ee-47b4-8f02-fc187fe0ebac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.8860698875801749\nAccuracy: 0.825905936777178\nRecall: 0.825905936777178\nF1 Score: 0.801125231731012\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Binary classification evaluator for area under ROC\n",
    "bcEvaluator2 = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "print(f\"Area under ROC curve: {bcEvaluator2.evaluate(predDF2)}\")\n",
    "\n",
    "# Multi-class classification evaluator for accuracy\n",
    "mcEvaluator2 = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(f\"Accuracy: {mcEvaluator2.evaluate(predDF2)}\")\n",
    "\n",
    "# Configure the evaluator for recall\n",
    "recallEvaluator2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "print(f\"Recall: {recallEvaluator2.evaluate(predDF2)}\")\n",
    "\n",
    "multi_evaluator_f2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "print(f\"F1 Score: {multi_evaluator_f2.evaluate(predDF2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d696c34-801d-4f91-9c7a-668da2b04fcd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Etape 4 : Réglage des paramétre (Random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecfe73b8-50fb-457b-903e-9740c5ecb21a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad98e7c5-3a0e-4353-b000-9cc9ebc361ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "paramGrid2 = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 30]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ba73e4d-28d0-4011-918a-7f0a10f53bcb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bcEvaluator2 = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "crossval2 = CrossValidator(estimator=pipeline2,\n",
    "                          estimatorParamMaps=paramGrid2,\n",
    "                          evaluator=bcEvaluator,\n",
    "                          numFolds=5)  # 5 plis est un bon point de départ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6c5555e-8ee3-464f-873f-15445fecf238",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "cvModel2 = crossval2.fit(trainDF)\n",
    "\n",
    "# Obtenir le meilleur modèle\n",
    "bestModel = cvModel2.bestModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "220ee0ea-ae64-44ce-981e-ef5765656e51",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Faire des prédictions\n",
    "predictions2 = bestModel.transform(testDF)\n",
    "\n",
    "# Évaluateur pour l'aire sous la courbe ROC\n",
    "bcEvaluator2 = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "auc2 = bcEvaluator2.evaluate(predictions2)\n",
    "accuracyEvaluator2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy2 = accuracyEvaluator2.evaluate(predictions2)\n",
    "recallEvaluator2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "weightedRecall2 = recallEvaluator2.evaluate(predictions2)\n",
    "multi_evaluator_f2 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "\n",
    "print(f\"Area under ROC curve (AUC): {auc2}\")\n",
    "print(f\"Accuracy: {accuracy2}\")\n",
    "print(f\"Weighted Recall: {weightedRecall2}\")\n",
    "print(f\"F1 Score: {multi_evaluator_f2.evaluate(predictions2)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SupervisedLearning_Aghilas_SMAIL",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
