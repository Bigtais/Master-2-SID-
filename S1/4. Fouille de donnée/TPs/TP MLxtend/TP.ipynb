{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Obtaining dependency information for mlxtend from https://files.pythonhosted.org/packages/73/da/d5d77a9a7a135c948dbf8d3b873655b105a152d69e590150c83d23c3d070/mlxtend-0.23.0-py3-none-any.whl.metadata\n",
      "  Downloading mlxtend-0.23.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from mlxtend) (1.11.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from mlxtend) (1.26.0)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from mlxtend) (2.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from mlxtend) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from mlxtend) (3.8.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from mlxtend) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aghil\\anaconda3\\envs\\tp1\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Downloading mlxtend-0.23.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.4 MB 1.3 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.4 MB 487.6 kB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.1/1.4 MB 655.4 kB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.1/1.4 MB 774.0 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 888.4 kB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.4 MB 1.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.3/1.4 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.4/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.5/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.6/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.6/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.7/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.7/1.4 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.8/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.4 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.9/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.0/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.2/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.2/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.3/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.4/1.4 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1360, 303)\n",
      "Index(['100_Watt_Lightbulb', '2pct_Milk', '40_Watt_Lightbulb',\n",
      "       '60_Watt_Lightbulb', '75_Watt_Lightbulb', '98pct_Fat_Free_Hamburger',\n",
      "       'AA_Cell_Batteries', 'Apple_Cinnamon_Waffles', 'Apple_Drink',\n",
      "       'Apple_Fruit_Roll',\n",
      "       ...\n",
      "       'White_Bread', 'White_Wine', 'White_Zinfandel_Wine', 'Whole_Corn',\n",
      "       'Whole_Green_Beans', 'Whole_Milk', 'Window_Cleaner', 'Wood_Polish',\n",
      "       'flav_Fruit_Bars', 'flav_Ice'],\n",
      "      dtype='object', length=303)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import chdir\n",
    "#chdir(\"\")\n",
    "dataset = pd.read_csv('Jeux\\market_basket.csv', header=0)\n",
    "#vérifications\n",
    "print(dataset.shape) #(1360, 303)\n",
    "print(dataset.columns)\n",
    "# transformation en valeurs booléennes (étape non obligatoire mais\n",
    "# recommandée par MLxtend)\n",
    "for col in dataset.columns:\n",
    "    dataset[col] = dataset[col].map({1 : True, 0 : False})\n",
    "    dataset[col].astype(\"boolean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603, 2)\n",
      "Index(['support', 'itemsets'], dtype='object')\n",
      "     support                    itemsets\n",
      "0   0.030147        (100_Watt_Lightbulb)\n",
      "1   0.109559                 (2pct_Milk)\n",
      "2   0.037500         (60_Watt_Lightbulb)\n",
      "3   0.031618         (75_Watt_Lightbulb)\n",
      "4   0.093382  (98pct_Fat_Free_Hamburger)\n",
      "5   0.031618         (AA_Cell_Batteries)\n",
      "6   0.025735    (Apple_Cinnamon_Waffles)\n",
      "7   0.026471               (Apple_Drink)\n",
      "8   0.031618          (Apple_Fruit_Roll)\n",
      "9   0.032353                 (Apple_Jam)\n",
      "10  0.033088               (Apple_Jelly)\n",
      "11  0.032353               (Apple_Sauce)\n",
      "12  0.053676                    (Apples)\n",
      "13  0.066912                   (Aspirin)\n",
      "14  0.027941               (Avocado_Dip)\n",
      "<class 'pandas.core.series.Series'>\n",
      "frozenset({'100_Watt_Lightbulb'})\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "taillemax = 4\n",
    "freq_itemsets = apriori(dataset, min_support=0.025, max_len=taillemax,\n",
    "use_colnames=True, verbose=0)\n",
    "#type du résultat\n",
    "type(freq_itemsets)\n",
    "#nombre de motifs obtenus\n",
    "print(freq_itemsets.shape) # (603, 2) ; 603 motifs fréquents\n",
    "#liste des colonnes\n",
    "print(freq_itemsets.columns)\n",
    "#affichage des 15 premiers motifs\n",
    "print(freq_itemsets.head(15))\n",
    "#type de la colonne ’itemsets’\n",
    "print(type(freq_itemsets.itemsets))\n",
    "#affichage du premier élément\n",
    "print(freq_itemsets.itemsets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(105, 10)\n",
      "Index(['antecedents', 'consequents', 'antecedent support',\n",
      "       'consequent support', 'support', 'confidence', 'lift', 'leverage',\n",
      "       'conviction', 'zhangs_metric'],\n",
      "      dtype='object')\n",
      "                             antecedents     consequents  antecedent support  \\\n",
      "0                         (Hot_Dog_Buns)      (Hot_Dogs)            0.058824   \n",
      "1  (98pct_Fat_Free_Hamburger, 2pct_Milk)          (Eggs)            0.038235   \n",
      "2  (98pct_Fat_Free_Hamburger, 2pct_Milk)  (Potato_Chips)            0.038235   \n",
      "3                   (Aspirin, 2pct_Milk)          (Eggs)            0.034559   \n",
      "4                   (Aspirin, 2pct_Milk)  (Potato_Chips)            0.034559   \n",
      "\n",
      "   consequent support   support  confidence      lift  leverage  conviction  \\\n",
      "0            0.092647  0.041912    0.712500  7.690476  0.036462    3.156010   \n",
      "1            0.122794  0.027206    0.711538  5.794565  0.022511    3.040980   \n",
      "2            0.097794  0.027206    0.711538  7.275882  0.023467    3.127647   \n",
      "3            0.122794  0.025735    0.744681  6.064467  0.021492    3.435723   \n",
      "4            0.097794  0.025000    0.723404  7.397216  0.021620    3.261821   \n",
      "\n",
      "   zhangs_metric  \n",
      "0       0.924342  \n",
      "1       0.860319  \n",
      "2       0.896851  \n",
      "3       0.864998  \n",
      "4       0.895771  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "arules = association_rules(freq_itemsets, metric=\"confidence\",\n",
    "min_threshold=0.7)\n",
    "#type du résultat\n",
    "print(type(arules))\n",
    "#nombre de règles générées\n",
    "print(arules.shape) # (50, 9)\n",
    "#liste des colonnes\n",
    "print(arules.columns)\n",
    "#affichage des 5 premières règles du résultat\n",
    "print(arules.iloc[:5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(105, 4)\n",
      "                             antecedents     consequents   lift  conviction\n",
      "0                         (Hot_Dog_Buns)      (Hot_Dogs)  7.690       3.156\n",
      "1  (98pct_Fat_Free_Hamburger, 2pct_Milk)          (Eggs)  5.795       3.041\n",
      "2  (98pct_Fat_Free_Hamburger, 2pct_Milk)  (Potato_Chips)  7.276       3.128\n",
      "3                   (Aspirin, 2pct_Milk)          (Eggs)  6.064       3.436\n",
      "4                   (Aspirin, 2pct_Milk)  (Potato_Chips)  7.397       3.262\n",
      "5                   (Aspirin, 2pct_Milk)   (White_Bread)  6.609       4.140\n",
      "6                 (Bananas, White_Bread)     (2pct_Milk)  7.261       4.353\n",
      "7                   (Bananas, 2pct_Milk)   (White_Bread)  6.833       4.735\n",
      "8                           (Cola, Eggs)     (2pct_Milk)  6.638       3.265\n",
      "9                      (Cola, 2pct_Milk)          (Eggs)  5.923       3.216\n",
      "                                 antecedents     consequents   lift  \\\n",
      "0                             (Hot_Dog_Buns)      (Hot_Dogs)  7.690   \n",
      "2      (98pct_Fat_Free_Hamburger, 2pct_Milk)  (Potato_Chips)  7.276   \n",
      "4                       (Aspirin, 2pct_Milk)  (Potato_Chips)  7.397   \n",
      "6                     (Bananas, White_Bread)     (2pct_Milk)  7.261   \n",
      "11                       (Cola, Wheat_Bread)     (2pct_Milk)  7.261   \n",
      "..                                       ...             ...    ...   \n",
      "100           (Eggs, White_Bread, 2pct_Milk)    (Toothpaste)  8.995   \n",
      "101  (Toothpaste, White_Bread, Potato_Chips)     (2pct_Milk)  7.569   \n",
      "102    (Toothpaste, 2pct_Milk, Potato_Chips)   (White_Bread)  7.319   \n",
      "103     (Toothpaste, White_Bread, 2pct_Milk)  (Potato_Chips)  7.726   \n",
      "104   (Potato_Chips, White_Bread, 2pct_Milk)    (Toothpaste)  9.514   \n",
      "\n",
      "     conviction  \n",
      "0         3.156  \n",
      "2         3.128  \n",
      "4         3.262  \n",
      "6         4.353  \n",
      "11        4.353  \n",
      "..          ...  \n",
      "100       3.222  \n",
      "101       5.215  \n",
      "102       6.871  \n",
      "103       3.691  \n",
      "104       3.766  \n",
      "\n",
      "[22 rows x 4 columns]\n",
      "                                 antecedents                 consequents  \\\n",
      "104   (Potato_Chips, White_Bread, 2pct_Milk)                (Toothpaste)   \n",
      "79              (Hot_Dog_Buns, Sweet_Relish)                  (Hot_Dogs)   \n",
      "100           (Eggs, White_Bread, 2pct_Milk)                (Toothpaste)   \n",
      "78                  (Hot_Dogs, Hot_Dog_Buns)              (Sweet_Relish)   \n",
      "43             (White_Bread, Hamburger_Buns)  (98pct_Fat_Free_Hamburger)   \n",
      "103     (Toothpaste, White_Bread, 2pct_Milk)              (Potato_Chips)   \n",
      "0                             (Hot_Dog_Buns)                  (Hot_Dogs)   \n",
      "29                     (Wheat_Bread, Onions)                 (2pct_Milk)   \n",
      "101  (Toothpaste, White_Bread, Potato_Chips)                 (2pct_Milk)   \n",
      "45   (Wheat_Bread, 98pct_Fat_Free_Hamburger)               (White_Bread)   \n",
      "\n",
      "      lift  conviction  \n",
      "104  9.514       3.766  \n",
      "79   9.031       5.558  \n",
      "100  8.995       3.222  \n",
      "78   8.433       3.259  \n",
      "43   8.202       3.874  \n",
      "103  7.726       3.691  \n",
      "0    7.690       3.156  \n",
      "29   7.574       5.231  \n",
      "101  7.569       5.215  \n",
      "45   7.556       8.809  \n",
      "                               antecedents consequents   lift  conviction\n",
      "1    (98pct_Fat_Free_Hamburger, 2pct_Milk)      (Eggs)  5.795       3.041\n",
      "3                     (Aspirin, 2pct_Milk)      (Eggs)  6.064       3.436\n",
      "9                        (Cola, 2pct_Milk)      (Eggs)  5.923       3.216\n",
      "14   (Pepperoni_Pizza_-_Frozen, 2pct_Milk)      (Eggs)  6.064       3.436\n",
      "16               (Popcorn_Salt, 2pct_Milk)      (Eggs)  6.696       4.934\n",
      "..                                     ...         ...    ...         ...\n",
      "70                 (Potatoes, White_Bread)      (Eggs)  5.897       3.180\n",
      "71            (White_Bread, Sugar_Cookies)      (Eggs)  6.277       3.828\n",
      "73              (Toothpaste, Sweet_Relish)      (Eggs)  5.749       2.983\n",
      "94  (Potato_Chips, White_Bread, 2pct_Milk)      (Eggs)  6.515       4.386\n",
      "98    (Toothpaste, White_Bread, 2pct_Milk)      (Eggs)  6.334       3.947\n",
      "\n",
      "[33 rows x 4 columns]\n",
      "                               antecedents consequents   lift  conviction\n",
      "1    (98pct_Fat_Free_Hamburger, 2pct_Milk)      (Eggs)  5.795       3.041\n",
      "3                     (Aspirin, 2pct_Milk)      (Eggs)  6.064       3.436\n",
      "9                        (Cola, 2pct_Milk)      (Eggs)  5.923       3.216\n",
      "14   (Pepperoni_Pizza_-_Frozen, 2pct_Milk)      (Eggs)  6.064       3.436\n",
      "16               (Popcorn_Salt, 2pct_Milk)      (Eggs)  6.696       4.934\n",
      "..                                     ...         ...    ...         ...\n",
      "70                 (Potatoes, White_Bread)      (Eggs)  5.897       3.180\n",
      "71            (White_Bread, Sugar_Cookies)      (Eggs)  6.277       3.828\n",
      "73              (Toothpaste, Sweet_Relish)      (Eggs)  5.749       2.983\n",
      "94  (Potato_Chips, White_Bread, 2pct_Milk)      (Eggs)  6.515       4.386\n",
      "98    (Toothpaste, White_Bread, 2pct_Milk)      (Eggs)  6.334       3.947\n",
      "\n",
      "[33 rows x 4 columns]\n",
      "                               antecedents consequents   lift  conviction\n",
      "16               (Popcorn_Salt, 2pct_Milk)      (Eggs)  6.696       4.934\n",
      "62                (Potatoes, Popcorn_Salt)      (Eggs)  6.593       4.605\n",
      "94  (Potato_Chips, White_Bread, 2pct_Milk)      (Eggs)  6.515       4.386\n",
      "69                (Potatoes, Sweet_Relish)      (Eggs)  6.482       4.298\n",
      "21                   (2pct_Milk, Tomatoes)      (Eggs)  6.478       4.289\n",
      "..                                     ...         ...    ...         ...\n",
      "58                 (Hot_Dogs, White_Bread)      (Eggs)  5.775       3.015\n",
      "51                    (Cola, Potato_Chips)      (Eggs)  5.768       3.008\n",
      "73              (Toothpaste, Sweet_Relish)      (Eggs)  5.749       2.983\n",
      "46                  (Aspirin, White_Bread)      (Eggs)  5.715       2.941\n",
      "25                (White_Bread, 2pct_Milk)      (Eggs)  5.701       2.924\n",
      "\n",
      "[33 rows x 4 columns]\n",
      "                               antecedents consequents   lift  conviction\n",
      "16               (Popcorn_Salt, 2pct_Milk)      (Eggs)  6.696       4.934\n",
      "94  (Potato_Chips, White_Bread, 2pct_Milk)      (Eggs)  6.515       4.386\n",
      "21                   (2pct_Milk, Tomatoes)      (Eggs)  6.478       4.289\n",
      "98    (Toothpaste, White_Bread, 2pct_Milk)      (Eggs)  6.334       3.947\n",
      "17               (Potato_Chips, 2pct_Milk)      (Eggs)  6.141       3.567\n",
      "..                                     ...         ...    ...         ...\n",
      "24                (Wheat_Bread, 2pct_Milk)      (Eggs)  5.897       3.180\n",
      "19               (2pct_Milk, Sweet_Relish)      (Eggs)  5.817       3.070\n",
      "22                 (Toothpaste, 2pct_Milk)      (Eggs)  5.797       3.044\n",
      "1    (98pct_Fat_Free_Hamburger, 2pct_Milk)      (Eggs)  5.795       3.041\n",
      "25                (White_Bread, 2pct_Milk)      (Eggs)  5.701       2.924\n",
      "\n",
      "[14 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "my_rules = arules.loc[:, ['antecedents','consequents', 'lift', 'conviction']]\n",
    "print(my_rules.shape)\n",
    "#pour un affichage plus lisible\n",
    "pd.set_option('display.max_columns', 6)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.precision', 3)\n",
    "# sélection des colonnes à afficher\n",
    "my_rules = arules.loc[:,['antecedents', 'consequents', 'lift', 'conviction']]\n",
    "print(my_rules.shape)\n",
    "#affichage des 5 premières règles\n",
    "print(my_rules[:10])\n",
    "#affichage des règles avec un lift supérieur ou égal à 7\n",
    "print(my_rules[my_rules['lift'].ge(7.0)])\n",
    "#trier les règles selon le lift (ordre décroissant) et afficher les 10\n",
    "#meilleures règles\n",
    "print(my_rules.sort_values(by='lift', ascending=False)[:10])\n",
    "#affichage des règles contenant ’Eggs’ dans le conséquent\n",
    "print(my_rules[my_rules['consequents'].ge({'Eggs'})])\n",
    "#affichage des règles où le conséquent est exactement ’Eggs’\n",
    "print(my_rules[my_rules['consequents'].eq({'Eggs'})])\n",
    "#idem mais en triant selon le lift (ordre décroissant)\n",
    "print(my_rules[my_rules['consequents'].eq({'Eggs'})].sort_values(by='lift', ascending=False))\n",
    "#affichage des règles avec ’2pct_Milk’ contenu dans l’antécédent et ’\n",
    "#Eggs' correspondant au conséquent\n",
    "print(my_rules[my_rules['antecedents'].ge({'2pct_Milk'}) & my_rules['consequents'].eq({'Eggs'})].sort_values(by='lift', ascending=False\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent itemsets: 34212\n",
      "Number of association rules: 61916\n",
      "            antecedents  consequents  antecedent support  ...  leverage  \\\n",
      "0  (100_Watt_Lightbulb)       (Eggs)               0.030  ...     0.015   \n",
      "1   (AA_Cell_Batteries)  (2pct_Milk)               0.032  ...     0.019   \n",
      "2    (Apple_Fruit_Roll)  (2pct_Milk)               0.032  ...     0.019   \n",
      "3         (Apple_Jelly)  (2pct_Milk)               0.033  ...     0.019   \n",
      "4         (Baked_Beans)  (2pct_Milk)               0.032  ...     0.017   \n",
      "\n",
      "   conviction  zhangs_metric  \n",
      "0       2.248          0.823  \n",
      "1       2.945          0.870  \n",
      "2       2.945          0.870  \n",
      "3       2.862          0.870  \n",
      "4       2.449          0.856  \n",
      "\n",
      "[5 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Set the minimum support to 0.015\n",
    "min_support = 0.01\n",
    "\n",
    "# Generate frequent itemsets\n",
    "freq_itemsets = apriori(dataset, min_support=min_support, max_len=taillemax, use_colnames=True, verbose=0)\n",
    "\n",
    "# Generate association rules with minconf=0.7\n",
    "rules = association_rules(freq_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "# Display the number of frequent itemsets and association rules\n",
    "print(\"Number of frequent itemsets:\", freq_itemsets.shape[0])\n",
    "print(\"Number of association rules:\", rules.shape[0])\n",
    "\n",
    "# Display the first few association rules\n",
    "print(rules.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent itemsets: 4759\n",
      "Number of association rules: 3265\n",
      "                 antecedents  consequents  antecedent support  ...  leverage  \\\n",
      "0               (Buttermilk)  (2pct_Milk)               0.025  ...     0.015   \n",
      "1     (Dishwasher_Detergent)  (2pct_Milk)               0.029  ...     0.017   \n",
      "2  (Mushroom_Pizza_-_Frozen)  (2pct_Milk)               0.025  ...     0.016   \n",
      "3                   (Sponge)  (2pct_Milk)               0.027  ...     0.016   \n",
      "4        (Whole_Green_Beans)  (2pct_Milk)               0.022  ...     0.013   \n",
      "\n",
      "   conviction  zhangs_metric  \n",
      "0       3.027          0.866  \n",
      "1       2.968          0.869  \n",
      "2       3.364          0.873  \n",
      "3       2.995          0.868  \n",
      "4       2.968          0.863  \n",
      "\n",
      "[5 rows x 10 columns]\n",
      "Number of interesting rules: 3130\n",
      "                                   antecedents    consequents  \\\n",
      "0                                 (Buttermilk)    (2pct_Milk)   \n",
      "2                    (Mushroom_Pizza_-_Frozen)    (2pct_Milk)   \n",
      "3                                     (Sponge)    (2pct_Milk)   \n",
      "5                                (Apple_Jelly)  (White_Bread)   \n",
      "6                             (Canned_Peaches)  (White_Bread)   \n",
      "...                                        ...            ...   \n",
      "3259      (Toothpaste, Sweet_Relish, Tomatoes)  (White_Bread)   \n",
      "3260     (Sweet_Relish, White_Bread, Tomatoes)   (Toothpaste)   \n",
      "3261   (Toothpaste, Wheat_Bread, Sweet_Relish)  (White_Bread)   \n",
      "3262  (Wheat_Bread, White_Bread, Sweet_Relish)   (Toothpaste)   \n",
      "3263       (Toothpaste, Wheat_Bread, Tomatoes)  (White_Bread)   \n",
      "\n",
      "      antecedent support  ...  leverage  conviction  zhangs_metric  \n",
      "0                  0.025  ...     0.015       3.027          0.866  \n",
      "2                  0.025  ...     0.016       3.364          0.873  \n",
      "3                  0.027  ...     0.016       2.995          0.868  \n",
      "5                  0.033  ...     0.020       3.049          0.861  \n",
      "6                  0.026  ...     0.016       3.426          0.862  \n",
      "...                  ...  ...       ...         ...            ...  \n",
      "3259               0.018  ...     0.013       5.506          0.874  \n",
      "3260               0.021  ...     0.014       3.337          0.910  \n",
      "3261               0.020  ...     0.013       3.964          0.864  \n",
      "3262               0.021  ...     0.014       3.337          0.910  \n",
      "3263               0.019  ...     0.013       4.581          0.869  \n",
      "\n",
      "[3130 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Trouvez quelques règles qui vous semblent intéressantes.\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Set the minimum support to 0.015 and other parameters\n",
    "taillemax = 4\n",
    "min_support = 0.015\n",
    "min_confidence = 0.7\n",
    "\n",
    "# Generate frequent itemsets\n",
    "freq_itemsets = apriori(dataset, min_support=min_support, max_len=taillemax, use_colnames=True, verbose=0)\n",
    "\n",
    "# Generate association rules with minconf=0.7\n",
    "rules = association_rules(freq_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Display the number of frequent itemsets and association rules\n",
    "print(\"Number of frequent itemsets:\", freq_itemsets.shape[0])\n",
    "print(\"Number of association rules:\", rules.shape[0])\n",
    "\n",
    "# Display the first few association rules\n",
    "print(rules.head())\n",
    "\n",
    "# Filter rules based on desired criteria\n",
    "interesting_rules = rules[(rules['support'] > min_support) & (rules['confidence'] > min_confidence)]\n",
    "\n",
    "# Display the interesting rules\n",
    "print(\"Number of interesting rules:\", interesting_rules.shape[0])\n",
    "print(interesting_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 antecedents                 consequents  \\\n",
      "0                             (Hot_Dog_Buns)                  (Hot_Dogs)   \n",
      "43             (Hamburger_Buns, White_Bread)  (98pct_Fat_Free_Hamburger)   \n",
      "44  (98pct_Fat_Free_Hamburger, Potato_Chips)               (White_Bread)   \n",
      "45   (98pct_Fat_Free_Hamburger, Wheat_Bread)               (White_Bread)   \n",
      "48                   (Aspirin, Potato_Chips)               (White_Bread)   \n",
      "..                                       ...                         ...   \n",
      "88                    (Potatoes, Toothpaste)               (White_Bread)   \n",
      "89                (Toothpaste, Sweet_Relish)               (White_Bread)   \n",
      "90                (Toothpaste, Toilet_Paper)               (White_Bread)   \n",
      "91                    (Tomatoes, Toothpaste)               (White_Bread)   \n",
      "92                 (Wheat_Bread, Toothpaste)               (White_Bread)   \n",
      "\n",
      "     lift  conviction  \n",
      "0   7.690       3.156  \n",
      "43  8.202       3.874  \n",
      "44  5.976       3.057  \n",
      "45  7.556       8.809  \n",
      "48  6.339       3.597  \n",
      "..    ...         ...  \n",
      "88  6.678       4.307  \n",
      "89  6.255       3.456  \n",
      "90  7.346       7.047  \n",
      "91  6.996       5.285  \n",
      "92  6.430       3.764  \n",
      "\n",
      "[22 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les règles pour exclure celles qui incluent \"Milk\", \"Eggs\", et \"Cola\"\n",
    "excluded_items = {\"2pct_Milk\", \"Eggs\", \"Cola\"}\n",
    "filtered_rules = my_rules[~my_rules[\"antecedents\"].apply(lambda x: any(item in excluded_items for item in x)) &\n",
    "                          ~my_rules[\"consequents\"].apply(lambda x: any(item in excluded_items for item in x))]\n",
    "\n",
    "# Afficher les règles filtrées\n",
    "print(filtered_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1079, 303)\n"
     ]
    }
   ],
   "source": [
    "# Items to be excluded\n",
    "excluded_items = [\"2pct_Milk\", \"Eggs\", \"Cola\"]\n",
    "\n",
    "# Filter transactions to exclude those containing specified items\n",
    "filtered_dataset = dataset[~dataset[excluded_items].any(axis=1)]\n",
    "\n",
    "# Print the shape of the filtered dataset for verification\n",
    "print(filtered_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlrd>=2.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 antecedents     consequents   lift  \\\n",
      "5                       (Aspirin, 2pct_Milk)   (White_Bread)  6.609   \n",
      "6                     (Bananas, White_Bread)     (2pct_Milk)  7.261   \n",
      "7                       (Bananas, 2pct_Milk)   (White_Bread)  6.833   \n",
      "12                       (Cola, White_Bread)     (2pct_Milk)  6.804   \n",
      "13                         (Cola, 2pct_Milk)   (White_Bread)  6.258   \n",
      "..                                       ...             ...    ...   \n",
      "100           (Eggs, White_Bread, 2pct_Milk)    (Toothpaste)  8.995   \n",
      "101  (Toothpaste, White_Bread, Potato_Chips)     (2pct_Milk)  7.569   \n",
      "102    (Toothpaste, 2pct_Milk, Potato_Chips)   (White_Bread)  7.319   \n",
      "103     (Toothpaste, White_Bread, 2pct_Milk)  (Potato_Chips)  7.726   \n",
      "104   (Potato_Chips, White_Bread, 2pct_Milk)    (Toothpaste)  9.514   \n",
      "\n",
      "     conviction  \n",
      "5         4.140  \n",
      "6         4.353  \n",
      "7         4.735  \n",
      "12        3.498  \n",
      "13        3.461  \n",
      "..          ...  \n",
      "100       3.222  \n",
      "101       5.215  \n",
      "102       6.871  \n",
      "103       3.691  \n",
      "104       3.766  \n",
      "\n",
      "[63 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les règles pour inclure uniquement celles associées à \"White_Bread\"\n",
    "white_bread_associations = my_rules[my_rules[\"antecedents\"].apply(lambda x: \"White_Bread\" in x) | my_rules[\"consequents\"].apply(lambda x: \"White_Bread\" in x)]\n",
    "\n",
    "# Afficher toutes les colonnes\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(white_bread_associations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  antecedents                 consequents  \\\n",
      "5                        (Aspirin, 2pct_Milk)               (White_Bread)   \n",
      "6                      (Bananas, White_Bread)                 (2pct_Milk)   \n",
      "7                        (Bananas, 2pct_Milk)               (White_Bread)   \n",
      "12                        (Cola, White_Bread)                 (2pct_Milk)   \n",
      "13                          (Cola, 2pct_Milk)               (White_Bread)   \n",
      "25                   (White_Bread, 2pct_Milk)                      (Eggs)   \n",
      "26                      (Hot_Dogs, 2pct_Milk)               (White_Bread)   \n",
      "33                  (Potato_Chips, 2pct_Milk)               (White_Bread)   \n",
      "35                      (Potatoes, 2pct_Milk)               (White_Bread)   \n",
      "36                  (Toilet_Paper, 2pct_Milk)               (White_Bread)   \n",
      "37                      (2pct_Milk, Tomatoes)               (White_Bread)   \n",
      "39                    (Toothpaste, 2pct_Milk)               (White_Bread)   \n",
      "40                 (Wheat_Bread, White_Bread)                 (2pct_Milk)   \n",
      "41                   (Wheat_Bread, 2pct_Milk)               (White_Bread)   \n",
      "43              (White_Bread, Hamburger_Buns)  (98pct_Fat_Free_Hamburger)   \n",
      "44   (Potato_Chips, 98pct_Fat_Free_Hamburger)               (White_Bread)   \n",
      "45    (Wheat_Bread, 98pct_Fat_Free_Hamburger)               (White_Bread)   \n",
      "46                     (Aspirin, White_Bread)                      (Eggs)   \n",
      "47                            (Aspirin, Eggs)               (White_Bread)   \n",
      "48                    (Aspirin, Potato_Chips)               (White_Bread)   \n",
      "49                        (Aspirin, Potatoes)               (White_Bread)   \n",
      "50                      (Aspirin, Toothpaste)               (White_Bread)   \n",
      "52                        (Cola, White_Bread)                      (Eggs)   \n",
      "53                               (Cola, Eggs)               (White_Bread)   \n",
      "54                       (Cola, Potato_Chips)               (White_Bread)   \n",
      "55                         (Cola, Toothpaste)               (White_Bread)   \n",
      "56                        (Cola, Wheat_Bread)               (White_Bread)   \n",
      "58                    (Hot_Dogs, White_Bread)                      (Eggs)   \n",
      "61    (Pepperoni_Pizza_-_Frozen, White_Bread)                      (Eggs)   \n",
      "63                (Popcorn_Salt, White_Bread)                      (Eggs)   \n",
      "64                       (Popcorn_Salt, Eggs)               (White_Bread)   \n",
      "70                    (Potatoes, White_Bread)                      (Eggs)   \n",
      "71               (White_Bread, Sugar_Cookies)                      (Eggs)   \n",
      "72                      (Eggs, Sugar_Cookies)               (White_Bread)   \n",
      "74                       (Toilet_Paper, Eggs)               (White_Bread)   \n",
      "75                           (Eggs, Tomatoes)               (White_Bread)   \n",
      "76                         (Toothpaste, Eggs)               (White_Bread)   \n",
      "77                        (Wheat_Bread, Eggs)               (White_Bread)   \n",
      "80                   (Hot_Dogs, Potato_Chips)               (White_Bread)   \n",
      "81                     (Potato_Chips, Onions)               (White_Bread)   \n",
      "82                       (Toothpaste, Onions)               (White_Bread)   \n",
      "83                   (Potatoes, Potato_Chips)               (White_Bread)   \n",
      "84                   (Potato_Chips, Tomatoes)               (White_Bread)   \n",
      "85                 (Toothpaste, Potato_Chips)               (White_Bread)   \n",
      "86                (Wheat_Bread, Potato_Chips)               (White_Bread)   \n",
      "87                   (Toilet_Paper, Potatoes)               (White_Bread)   \n",
      "88                     (Potatoes, Toothpaste)               (White_Bread)   \n",
      "89                 (Toothpaste, Sweet_Relish)               (White_Bread)   \n",
      "90                 (Toilet_Paper, Toothpaste)               (White_Bread)   \n",
      "91                     (Toothpaste, Tomatoes)               (White_Bread)   \n",
      "92                  (Toothpaste, Wheat_Bread)               (White_Bread)   \n",
      "93          (Eggs, Potato_Chips, White_Bread)                 (2pct_Milk)   \n",
      "94     (Potato_Chips, White_Bread, 2pct_Milk)                      (Eggs)   \n",
      "95            (Potato_Chips, Eggs, 2pct_Milk)               (White_Bread)   \n",
      "96             (Eggs, White_Bread, 2pct_Milk)              (Potato_Chips)   \n",
      "97            (Eggs, Toothpaste, White_Bread)                 (2pct_Milk)   \n",
      "98       (Toothpaste, White_Bread, 2pct_Milk)                      (Eggs)   \n",
      "99              (Toothpaste, Eggs, 2pct_Milk)               (White_Bread)   \n",
      "100            (Eggs, White_Bread, 2pct_Milk)                (Toothpaste)   \n",
      "101   (Toothpaste, White_Bread, Potato_Chips)                 (2pct_Milk)   \n",
      "102     (Toothpaste, 2pct_Milk, Potato_Chips)               (White_Bread)   \n",
      "103      (Toothpaste, White_Bread, 2pct_Milk)              (Potato_Chips)   \n",
      "104    (Potato_Chips, White_Bread, 2pct_Milk)                (Toothpaste)   \n",
      "\n",
      "      lift  conviction  \n",
      "5    6.609       4.140  \n",
      "6    7.261       4.353  \n",
      "7    6.833       4.735  \n",
      "12   6.804       3.498  \n",
      "13   6.258       3.461  \n",
      "25   5.701       2.924  \n",
      "26   6.019       3.112  \n",
      "33   6.193       3.358  \n",
      "35   6.458       3.817  \n",
      "36   5.947       3.020  \n",
      "37   6.678       4.307  \n",
      "39   6.403       3.712  \n",
      "40   6.652       3.284  \n",
      "41   6.224       3.406  \n",
      "43   8.202       3.874  \n",
      "44   5.976       3.057  \n",
      "45   7.556       8.809  \n",
      "46   5.715       2.941  \n",
      "47   6.458       3.817  \n",
      "48   6.339       3.597  \n",
      "49   6.962       5.159  \n",
      "50   6.996       5.285  \n",
      "52   6.071       3.446  \n",
      "53   6.258       3.461  \n",
      "54   5.947       3.020  \n",
      "55   6.073       3.185  \n",
      "56   6.487       3.876  \n",
      "58   5.775       3.015  \n",
      "61   6.196       3.668  \n",
      "63   6.277       3.828  \n",
      "64   6.212       3.388  \n",
      "70   5.897       3.180  \n",
      "71   6.277       3.828  \n",
      "72   6.212       3.388  \n",
      "74   5.996       3.083  \n",
      "75   6.044       3.146  \n",
      "76   6.055       3.161  \n",
      "77   6.258       3.461  \n",
      "80   6.168       3.320  \n",
      "81   6.339       3.597  \n",
      "82   6.471       3.844  \n",
      "83   6.212       3.388  \n",
      "84   6.678       4.307  \n",
      "85   6.749       4.493  \n",
      "86   6.753       4.502  \n",
      "87   7.319       6.871  \n",
      "88   6.678       4.307  \n",
      "89   6.255       3.456  \n",
      "90   7.346       7.047  \n",
      "91   6.996       5.285  \n",
      "92   6.430       3.764  \n",
      "93   7.143       4.096  \n",
      "94   6.515       4.386  \n",
      "95   6.570       4.052  \n",
      "96   7.513       3.401  \n",
      "97   7.261       4.353  \n",
      "98   6.334       3.947  \n",
      "99   6.996       5.285  \n",
      "100  8.995       3.222  \n",
      "101  7.569       5.215  \n",
      "102  7.319       6.871  \n",
      "103  7.726       3.691  \n",
      "104  9.514       3.766  \n",
      "63\n"
     ]
    }
   ],
   "source": [
    "# Filtrer les règles pour inclure uniquement celles associées à \"White_Bread\"\n",
    "white_bread_associations = my_rules[my_rules[\"antecedents\"].apply(lambda x: \"White_Bread\" in x) | my_rules[\"consequents\"].apply(lambda x: \"White_Bread\" in x)]\n",
    "\n",
    "# Afficher toutes les colonnes et toutes les lignes\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Imprimer le DataFrame des règles associées à \"White_Bread\"\n",
    "print(white_bread_associations)\n",
    "print(len(white_bread_associations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pclass  survived                                             name  ...  \\\n",
      "0        1         1                    Allen, Miss. Elisabeth Walton  ...   \n",
      "1        1         1                   Allison, Master. Hudson Trevor  ...   \n",
      "2        1         0                     Allison, Miss. Helen Loraine  ...   \n",
      "3        1         0             Allison, Mr. Hudson Joshua Creighton  ...   \n",
      "4        1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  ...   \n",
      "..     ...       ...                                              ...  ...   \n",
      "15       1         0                              Baumann, Mr. John D  ...   \n",
      "16       1         0                         Baxter, Mr. Quigg Edmond  ...   \n",
      "17       1         1  Baxter, Mrs. James (Helene DeLaudeniere Chaput)  ...   \n",
      "18       1         1                            Bazzani, Miss. Albina  ...   \n",
      "19       1         0                             Beattie, Mr. Thomson  ...   \n",
      "\n",
      "   boat   body                        home.dest  \n",
      "0     2    NaN                     St Louis, MO  \n",
      "1    11    NaN  Montreal, PQ / Chesterville, ON  \n",
      "2   NaN    NaN  Montreal, PQ / Chesterville, ON  \n",
      "3   NaN  135.0  Montreal, PQ / Chesterville, ON  \n",
      "4   NaN    NaN  Montreal, PQ / Chesterville, ON  \n",
      "..  ...    ...                              ...  \n",
      "15  NaN    NaN                     New York, NY  \n",
      "16  NaN    NaN                     Montreal, PQ  \n",
      "17    6    NaN                     Montreal, PQ  \n",
      "18    8    NaN                              NaN  \n",
      "19    A    NaN                     Winnipeg, MN  \n",
      "\n",
      "[20 rows x 14 columns]\n",
      "(1309, 14)\n",
      "Index(['pclass', 'survived', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n",
      "       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n",
      "      dtype='object')\n",
      "pclass         int64\n",
      "survived       int64\n",
      "name          object\n",
      "sex           object\n",
      "age          float64\n",
      "              ...   \n",
      "cabin         object\n",
      "embarked      object\n",
      "boat          object\n",
      "body         float64\n",
      "home.dest     object\n",
      "Length: 14, dtype: object\n",
      "   pclass  survived                                             name  ...  \\\n",
      "0       1         1                    Allen, Miss. Elisabeth Walton  ...   \n",
      "1       1         1                   Allison, Master. Hudson Trevor  ...   \n",
      "2       1         0                     Allison, Miss. Helen Loraine  ...   \n",
      "3       1         0             Allison, Mr. Hudson Joshua Creighton  ...   \n",
      "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  ...   \n",
      "\n",
      "  boat   body                        home.dest  \n",
      "0    2    NaN                     St Louis, MO  \n",
      "1   11    NaN  Montreal, PQ / Chesterville, ON  \n",
      "2  NaN    NaN  Montreal, PQ / Chesterville, ON  \n",
      "3  NaN  135.0  Montreal, PQ / Chesterville, ON  \n",
      "4  NaN    NaN  Montreal, PQ / Chesterville, ON  \n",
      "\n",
      "[5 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "'''import pandas as pd\n",
    "from os import chdir\n",
    "#chdir(\"mettre le chemin vers votre dossier de travail\")\n",
    "df = pd.read_excel('Jeux\\titanic3.xls')\n",
    "#vérification des données chargées\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "print(df.head())\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from os import chdir\n",
    "\n",
    "# Assuming 'Jeux' is a folder in the current directory\n",
    "# If not, provide the complete path to the file\n",
    "file_path = r'Jeux\\titanic3.xls'\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(file_path)\n",
    "print(df.head(20))\n",
    "# Verification of the loaded data\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Préparation des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 4)\n",
      "Index(['pclass', 'survived', 'sex', 'age'], dtype='object')\n",
      "   pclass  survived     sex     age\n",
      "0       1         1  female  29.000\n",
      "1       1         1    male   0.917\n",
      "2       1         0  female   2.000\n",
      "3       1         0    male  30.000\n",
      "4       1         0  female  25.000\n",
      "263\n",
      "(1046, 4)\n",
      "   pclass  survived     sex     age\n",
      "0       1         1  female  29.000\n",
      "1       1         1    male   0.917\n",
      "2       1         0  female   2.000\n",
      "3       1         0    male  30.000\n",
      "4       1         0  female  25.000\n",
      "False\n",
      "age\n",
      "adult    853\n",
      "child    193\n",
      "Name: count, dtype: int64\n",
      "   pclass  survived     sex     age   aged\n",
      "0       1         1  female  29.000  adult\n",
      "1       1         1    male   0.917  child\n",
      "2       1         0  female   2.000  child\n",
      "3       1         0    male  30.000  adult\n",
      "4       1         0  female  25.000  adult\n",
      "   pclass  survived     sex    age\n",
      "0       1         1  female  adult\n",
      "1       1         1    male  child\n",
      "2       1         0  female  child\n",
      "3       1         0    male  adult\n",
      "4       1         0  female  adult\n",
      "pclass        object\n",
      "survived      object\n",
      "sex           object\n",
      "age         category\n",
      "dtype: object\n",
      "pclass      category\n",
      "survived    category\n",
      "sex         category\n",
      "age         category\n",
      "dtype: object\n",
      "      pclass      survived         sex        age\n",
      "0  class=1st  survived=yes  sex=female  age=adult\n",
      "1  class=1st  survived=yes    sex=male  age=child\n",
      "2  class=1st   survived=no  sex=female  age=child\n",
      "3  class=1st   survived=no    sex=male  age=adult\n",
      "4  class=1st   survived=no  sex=female  age=adult\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "\n",
    "#on enlève les attributs non voulus\n",
    "df1 = df.drop(columns = ['name', 'ticket', 'home.dest', 'cabin', 'boat', 'body', 'sibsp', 'parch', 'fare', 'embarked'])\n",
    "print(df1.shape)\n",
    "print(df1.columns)\n",
    "print(df1.head())\n",
    "#ignorer les exemples où l'âge est inconnu\n",
    "print(df1['age'].isnull().sum())\n",
    "df2 = df1.dropna()\n",
    "print(df2.shape)\n",
    "print(df2.head())\n",
    "#reste-t-il des valeurs manquantes ?\n",
    "print(df2.isnull().values.any())\n",
    "#discrétisation de l'âge\n",
    "data = df2['age']\n",
    "agemin = data.min()\n",
    "agemax = data.max()\n",
    "datad = pd.cut(data, bins=[agemin, 18, agemax],\n",
    "labels=['child', 'adult'], include_lowest = True)\n",
    "#ici, au lieu d'indiquer le nombre d'intervalles (par exemple, \"bins\n",
    "#=2\"), on donne une liste de valeurs. Afin d'inclure le minimum, on\n",
    "#ajoute \"include_lowest=True\".\n",
    "\n",
    "print(datad.value_counts())\n",
    "df2.insert(4, \"aged\", datad, True)\n",
    "print(df2.head())\n",
    "df2 = df2.drop(columns = ['age'])\n",
    "df2 = df2.rename(columns={'aged': 'age'})\n",
    "print(df2.head())\n",
    "#renommage de valeurs\n",
    "df2['pclass'] = df2['pclass'].map({1:'class=1st', 2:'class=2nd', 3:'class=3rd'})\n",
    "df2['survived'] = df2['survived'].map({1:'survived=yes', 0:'survived=no'})\n",
    "df2['sex'] = df2['sex'].map({'female':'sex=female', 'male':'sex=male'})\n",
    "df2['age'] = df2['age'].map({'adult':'age=adult', 'child':'age=child'})\n",
    "#changement de types\n",
    "print(df2.dtypes)\n",
    "df2['pclass'] = df2['pclass'].astype('category')\n",
    "df2['survived'] = df2['survived'].astype('category')\n",
    "df2['sex'] = df2['sex'].astype('category')\n",
    "print(df2.dtypes)\n",
    "print(df2.head())\n",
    "#(facultatif) enregistrement des données préparées dans un fichier\n",
    "df2.to_csv('titanic.csv', header=True, index=False)\n",
    "#les données sont presque prêtes, il faut maintenant les mettre dans\n",
    "#le format accepté par MLxtend\n",
    "dataset = df2.values\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "dataset = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Découverte de règles d’association\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association Rules:\n",
      "     antecedents  consequents  antecedent support  consequent support  \\\n",
      "0     (sex=male)  (age=adult)               0.629               0.815   \n",
      "1  (survived=no)   (sex=male)               0.592               0.629   \n",
      "\n",
      "   support  confidence   lift  leverage  conviction  zhangs_metric  \n",
      "0    0.533       0.847  1.038     0.020       1.202          0.099  \n",
      "1    0.500       0.845  1.343     0.128       2.392          0.626  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Assuming df2 is your preprocessed DataFrame\n",
    "\n",
    "# Convert the DataFrame to the transaction format\n",
    "dataset = df2.values\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "dataset_transformed = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Calculate frequent itemsets with minsup = 0.5\n",
    "minsup_threshold = 0.5\n",
    "frequent_itemsets = apriori(dataset_transformed, min_support=minsup_threshold, use_colnames=True)\n",
    "\n",
    "# Generate association rules with minconf = 0.8\n",
    "minconf_threshold = 0.8\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=minconf_threshold)\n",
    "\n",
    "# Display the rules\n",
    "print(\"Association Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association Rules:\n",
      "                 antecedents            consequents  antecedent support  \\\n",
      "0                (class=3rd)            (age=adult)               0.479   \n",
      "1                 (sex=male)            (age=adult)               0.629   \n",
      "2              (survived=no)            (age=adult)               0.592   \n",
      "3             (survived=yes)            (age=adult)               0.408   \n",
      "4                (class=3rd)          (survived=no)               0.479   \n",
      "5                 (sex=male)          (survived=no)               0.629   \n",
      "6              (survived=no)             (sex=male)               0.592   \n",
      "7    (sex=male, survived=no)            (age=adult)               0.500   \n",
      "8      (sex=male, age=adult)          (survived=no)               0.533   \n",
      "9   (survived=no, age=adult)             (sex=male)               0.498   \n",
      "10             (survived=no)  (sex=male, age=adult)               0.592   \n",
      "\n",
      "    consequent support  support  confidence   lift  leverage  conviction  \\\n",
      "0                0.815    0.355       0.741  0.908    -0.036       0.711   \n",
      "1                0.815    0.533       0.847  1.038     0.020       1.202   \n",
      "2                0.815    0.498       0.842  1.032     0.016       1.165   \n",
      "3                0.815    0.317       0.778  0.953    -0.016       0.829   \n",
      "4                0.592    0.354       0.739  1.248     0.070       1.561   \n",
      "5                0.592    0.500       0.795  1.343     0.128       1.990   \n",
      "6                0.629    0.500       0.845  1.343     0.128       2.392   \n",
      "7                0.815    0.434       0.868  1.064     0.026       1.399   \n",
      "8                0.592    0.434       0.815  1.377     0.119       2.208   \n",
      "9                0.629    0.434       0.871  1.385     0.121       2.884   \n",
      "10               0.533    0.434       0.733  1.377     0.119       1.754   \n",
      "\n",
      "    zhangs_metric  \n",
      "0          -0.163  \n",
      "1           0.099  \n",
      "2           0.076  \n",
      "3          -0.076  \n",
      "4           0.381  \n",
      "5           0.689  \n",
      "6           0.626  \n",
      "7           0.121  \n",
      "8           0.586  \n",
      "9           0.554  \n",
      "10          0.671  \n"
     ]
    }
   ],
   "source": [
    "# Exemple en ajustant minsup et minconf\n",
    "# Note: Ceci est un exemple, ajustez les valeurs selon vos besoins spécifiques\n",
    "\n",
    "# Ajustez minsup en fonction de votre critère pour considérer les enfants\n",
    "minsup_threshold = 0.3  # Exemple: Si minsup n'est pas assez bas, les enfants ne seront pas considérés\n",
    "\n",
    "# Ajustez minconf en fonction de votre critère pour caractériser les survivants\n",
    "minconf_threshold = 0.7  # Exemple: Ajustez en fonction de vos besoins pour caractériser les survivants\n",
    "\n",
    "# Calculez les itemsets fréquents\n",
    "frequent_itemsets = apriori(dataset_transformed, min_support=minsup_threshold, use_colnames=True)\n",
    "\n",
    "# Générez les règles d'association\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=minconf_threshold)\n",
    "\n",
    "# Affichez les règles\n",
    "print(\"Association Rules:\")\n",
    "print(rules)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
